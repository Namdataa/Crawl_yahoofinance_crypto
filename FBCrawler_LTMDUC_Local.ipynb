{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Author notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone,\n",
    "\n",
    "Thank you for using my quick Facebook Scraping Python template. \n",
    "This solution leverages the library that called **facebook_scrapper** of **kevinzg**. \n",
    "\n",
    "You can learn more about this package at: https://pypi.org/project/facebook-scraper/\n",
    "\n",
    "I hope you can use this to develop your understanding in Social Listeners; Marketing; Market Insights; Sentiment Analysis;... and take this at the first step in Data Analytics world.\n",
    "\n",
    "I decide to share this works to my UFLL Vietnam (Unilever Future Leaders' League) fellows, friends, and you.\n",
    "\n",
    "Regards,\n",
    "Duc Lai\n",
    "\n",
    "ðŸ“§: me@henryduc.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9963,
     "status": "ok",
     "timestamp": 1650459579782,
     "user": {
      "displayName": "Duc Lai",
      "userId": "02994620237858814251"
     },
     "user_tz": -420
    },
    "id": "TEkUSyGsDC14",
    "outputId": "b7984777-6956-46e6-9084-fe01ce9e53e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facebook_scraper\n",
      "  Obtaining dependency information for facebook_scraper from https://files.pythonhosted.org/packages/14/3b/b8d70369a4ed461bb19b2547066ceaf3659ecf1bf5f27f8727225309f75f/facebook_scraper-0.2.59-py3-none-any.whl.metadata\n",
      "  Downloading facebook_scraper-0.2.59-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dateparser<2.0.0,>=1.0.0 (from facebook_scraper)\n",
      "  Obtaining dependency information for dateparser<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/a4/29/db12aa4dda81580be1999824a689bd52aa40061fc12c9ccdc3feab5ea718/dateparser-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting demjson3<4.0.0,>=3.0.5 (from facebook_scraper)\n",
      "  Downloading demjson3-3.0.6.tar.gz (131 kB)\n",
      "     ---------------------------------------- 0.0/131.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/131.5 kB ? eta -:--:--\n",
      "     ----------------- ------------------- 61.4/131.5 kB 825.8 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 112.6/131.5 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ 131.5/131.5 kB 777.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting requests-html<0.11.0,>=0.10.0 (from facebook_scraper)\n",
      "  Obtaining dependency information for requests-html<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil in e:\\jupyter\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2.8.2)\n",
      "Requirement already satisfied: pytz in e:\\jupyter\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2023.3.post1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in e:\\jupyter\\lib\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2022.7.9)\n",
      "Collecting tzlocal (from dateparser<2.0.0,>=1.0.0->facebook_scraper)\n",
      "  Obtaining dependency information for tzlocal from https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl.metadata\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: requests in e:\\jupyter\\lib\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.31.0)\n",
      "Collecting pyquery (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for pyquery from https://files.pythonhosted.org/packages/36/b7/f7ccf9e52e2817e1265d3719c600fa4ef33c07de4d5ef0ced3f43ab1cef2/pyquery-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fake-useragent (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for fake-useragent from https://files.pythonhosted.org/packages/e4/99/60d8cf1b26938c2e0a57e232f7f15641dfcd6f8deda454d73e4145910ff6/fake_useragent-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting parse (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for parse from https://files.pythonhosted.org/packages/ce/f0/30fe1494f1910ad3ea40639b13ac48cdb16a8600e8861cbfc2c560661ddf/parse-1.20.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading parse-1.20.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting bs4 (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for bs4 from https://files.pythonhosted.org/packages/51/bb/bf7aab772a159614954d84aa832c129624ba6c32faa559dfb200a534e50b/bs4-0.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: w3lib in e:\\jupyter\\lib\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.21.0)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for pyppeteer>=0.0.14 from https://files.pythonhosted.org/packages/3d/ee/fb2757a38025421fd3844a0ed0a230b78c9c04a66355024436cf3005a70c/pyppeteer-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in e:\\jupyter\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in e:\\jupyter\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2023.7.22)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in e:\\jupyter\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (6.0.0)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for pyee<12.0.0,>=11.0.0 from https://files.pythonhosted.org/packages/16/cc/5cea8a0a0d3deb90b5a0d39ad1a6a1ccaa40a9ea86d793eb8a49d32a6ed0/pyee-11.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in e:\\jupyter\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.65.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in e:\\jupyter\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.26.16)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for websockets<11.0,>=10.0 from https://files.pythonhosted.org/packages/27/bb/6327e8c7d4dd7d5b450b409a461be278968ce05c54da13da581ac87661db/websockets-10.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading websockets-10.4-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\jupyter\\lib\\site-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.12.2)\n",
      "Requirement already satisfied: lxml>=2.1 in e:\\jupyter\\lib\\site-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.9.3)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper)\n",
      "  Obtaining dependency information for cssselect>=1.2.0 from https://files.pythonhosted.org/packages/06/a9/2da08717a6862c48f1d61ef957a7bba171e7eefa6c0aa0ceb96a140c2a6b/cssselect-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\jupyter\\lib\\site-packages (from python-dateutil->dateparser<2.0.0,>=1.0.0->facebook_scraper) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\jupyter\\lib\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\jupyter\\lib\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.4)\n",
      "Requirement already satisfied: tzdata in e:\\jupyter\\lib\\site-packages (from tzlocal->dateparser<2.0.0,>=1.0.0->facebook_scraper) (2023.3)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\jupyter\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\jupyter\\lib\\site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.9.0)\n",
      "Requirement already satisfied: colorama in e:\\jupyter\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\jupyter\\lib\\site-packages (from beautifulsoup4->bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.4)\n",
      "Downloading facebook_scraper-0.2.59-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/295.0 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 194.6/295.0 kB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 286.7/295.0 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 295.0/295.0 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.9/82.9 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached websockets-10.4-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Building wheels for collected packages: demjson3\n",
      "  Building wheel for demjson3 (setup.py): started\n",
      "  Building wheel for demjson3 (setup.py): finished with status 'done'\n",
      "  Created wheel for demjson3: filename=demjson3-3.0.6-py3-none-any.whl size=75333 sha256=e741880f6f09d0694ad7c4912c35f20588e158078e2d640cea5d59b352b01fa3\n",
      "  Stored in directory: c:\\users\\windows.desktop-q6b5csd\\appdata\\local\\pip\\cache\\wheels\\3b\\9d\\d5\\e8cbb4d529989f6d3f347fe914559ea4f66715bf299763af1c\n",
      "Successfully built demjson3\n",
      "Installing collected packages: parse, fake-useragent, demjson3, websockets, tzlocal, pyee, cssselect, pyquery, pyppeteer, dateparser, bs4, requests-html, facebook_scraper\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 11.0.3\n",
      "    Uninstalling websockets-11.0.3:\n",
      "      Successfully uninstalled websockets-11.0.3\n",
      "  Attempting uninstall: cssselect\n",
      "    Found existing installation: cssselect 1.1.0\n",
      "    Uninstalling cssselect-1.1.0:\n",
      "      Successfully uninstalled cssselect-1.1.0\n",
      "Successfully installed bs4-0.0.2 cssselect-1.2.0 dateparser-1.2.0 demjson3-3.0.6 facebook_scraper-0.2.59 fake-useragent-1.5.1 parse-1.20.1 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests-html-0.10.0 tzlocal-5.2 websockets-10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install facebook_scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define WebPage & Storage Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650459584268,
     "user": {
      "displayName": "Duc Lai",
      "userId": "02994620237858814251"
     },
     "user_tz": -420
    },
    "id": "Gqfpmr97DIJV"
   },
   "outputs": [],
   "source": [
    "FANPAGE_LINK =\"groups/tuidepcaudep\"\n",
    "FOLDER_PATH = \"./\"\n",
    "PAGES_NUMBER = 5 # Posts-per-page = 4 => multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Source Ready To Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1650459587617,
     "user": {
      "displayName": "Duc Lai",
      "userId": "02994620237858814251"
     },
     "user_tz": -420
    },
    "id": "vYmaq7YQDJ2t"
   },
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling Start ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdrehHenDKyq",
    "outputId": "84862c77-849d-4ce1-b35f-369fa3c19916"
   },
   "outputs": [],
   "source": [
    "post_list = []\n",
    "for post in get_posts(FANPAGE_LINK, \n",
    "                    options={\"comments\": True, \"reactions\": True, \"allow_extra_requests\": True}, \n",
    "                    extra_info=True, pages=3):\n",
    "    post_list.append(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing & Output generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KzwaAiHADsv2"
   },
   "outputs": [],
   "source": [
    "fields_list = ['post_id', 'text', 'time', 'images', 'images_description', 'likes', 'comments', 'shares', 'post_url', 'link', 'username']\n",
    "result_list = []\n",
    "for post in post_list:\n",
    "    my_obj = {}\n",
    "    for field in fields_list:\n",
    "        my_obj[field] = post[field]\n",
    "    ## Manipulate Comments\n",
    "    if len(post['comments_full']) > 0:\n",
    "        my_obj['comments_content'] = '\\n'.join([comment['comment_text'] for comment in post['comments_full']])\n",
    "        my_obj['comments_time'] = '\\n'.join([comment['comment_time'].strftime(\"%Y-%m-%d-%H:%M:%S\") for comment in post['comments_full']])\n",
    "    \n",
    "    result_list.append(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ˜Ž Write it to CSV: <PAGE_NAME>.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "B01vey7aDw3B"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result_list)\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(FOLDER_PATH \u001b[38;5;241m+\u001b[39m FANPAGE_LINK \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\Jupyter\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mE:\\Jupyter\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mE:\\Jupyter\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mE:\\Jupyter\\Lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Jupyter\\Lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'groups'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(result_list)\n",
    "df.to_csv(FOLDER_PATH + FANPAGE_LINK + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPhmDz8ra+OkWt8zoeGkBW",
   "mount_file_id": "1YF734NvqneWWnyh1aBq9GjWxi761kfyW",
   "name": "FBCrawler_LTMDUC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
